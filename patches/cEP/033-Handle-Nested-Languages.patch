From 8274ea06fc9e856ff617ddf1c4d5d08ba49a86d4 Mon Sep 17 00:00:00 2001
From: Naveenaidu <naveennaidu479@gmail.com>
Date: Mon, 20 May 2019 16:10:03 +0530
Subject: [PATCH] cEP-0033: Handle Nested Programming Languages

Closes https://github.com/coala/cEPs/issues/187
---
 cEP-0033.md | 742 ++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 742 insertions(+)
 create mode 100644 cEP-0033.md

diff --git a/cEP-0033.md b/cEP-0033.md
new file mode 100644
index 00000000..4a1135ce
--- /dev/null
+++ b/cEP-0033.md
@@ -0,0 +1,742 @@
+# Handle Nested Programming Languages
+
+| Metadata |                                                |
+| -------- | ---------------------------------------------- |
+| cEP      | 0033                                           |
+| Version  | 0.1                                            |
+| Title    | Handle Nested Programming Language             |
+| Authors  | Naveen Naidu <mailto:naveennaidu479@gmail.com> |
+| Status   | Proposed                                       |
+| Type     | Feature                                        |
+
+## Abstract
+
+This cEP describes the architecture that needs to be implemented in order to
+enable coala to lint nested programming languages present in a file.
+
+## Introduction
+
+coala in its present state is capable of providing efficient static analysis 
+to only those file that contains a single programming language. But Multiple 
+programming languages can coexist in a single source file.Eg: `PHP and HTML` , 
+`HTML and Jinja` , `Python and Jinja` , `codeblocks and RST` etc.
+
+coala does not yet support these kind of files. This project would enable coala
+to deal with those situations and allow people to write code analysis similar to
+how they already do it while being applicable to the right locations at the
+right files.The users of coala would not have to concentrate on writing new 
+bears/ analysis routines. This implementation would perfectly work with the 
+existing bears. 
+
+There can be several ways to approach this. In this cEP, we will be implementing
+a abstract way which will support arbitrary combination of languages.
+
+## A higher level view of the implementation
+
+A source file containing multiple programming languages is loaded up by coala. 
+The original nested file is broken/split into `n` temporary files, where n is
+the number of languages present in the original file. Each temporary file only
+contains the snippets belonging to one language. 
+
+These temporary files would then be passed to their respective language bears 
+( _chosen by the user_) where the static analysis routines would run. The
+temporary files after being linted would then be assembled. 
+
+The above process creates the illusion that the original file is being linted, 
+but in reality we divide the files into different parts and lint them one by 
+one.
+
+The figure below, would help give a clear picture
+
+![higher_level_view](https://github.com/Naveenaidu/gsoc-18-materials/blob/master/photos/high_level_view_handle_nested.jpg)
+
+## Nested Language Section (nl_section)
+
+The original file is segregated into small pieces/units where each piece/unit
+purely contains only `one language`. These quantum pieces of the the nested 
+original file is termed as `nl_section`.
+
+A `nl_section` can further be defined as a group of lines in the source code that
+purely belongs to one particular language. 
+
+All the `nl_sections` that belong to one particular language are grouped to form
+a valid file of that programming language.
+
+The following figure would make the things clear
+
+![nl_sections](https://github.com/Naveenaidu/gsoc-18-materials/blob/master/photos/file_section.jpg)
+
+
+In the above figure, we have a file which contains both HTML and PHP code. This
+original file can be broken up into 4 different sections.
+
+Each nl_section will contain the following information:
+
+1. The Programming language of the lines
+2. Index of the section
+3. Starting Line number in the original file
+4. Ending Line number in the original file
+5. Starting line number in the linted file
+6. Ending line number in the linted file
+
+# Prototype of nl_section
+
+```python
+class NlSection(TextRange):
+
+    def __init__(self,
+                 orig_start: NlSectionPosition,
+                 orig_end: (NlSectionPosition, None) = None,
+                 index=None,
+                 language=None):
+        """
+        Creates a new NlSection.
+
+        :param orig_start:  A NlSectionPosition indicating the start of the 
+                            section in original file.
+        :param orig_end:    A NlSectionPosition indicating the end of the 
+                            section in the original file.
+                            If ``None`` is given, the start object will be used
+                            here. end must be in the same file and be greater
+                            than start as negative ranges are not allowed.
+        :param language:    The programming language of the lines.
+        :param index:       The index of the nl_section.
+        :raises TypeError:  Raised when
+                            - start is not of type NlSectionPosition.
+                            - end is neither of type NlSectionPosition, nor 
+                              is it None.
+        :raises ValueError: Raised when file of start and end mismatch.
+        """
+        TextRange.__init__(self, start, end)
+        self.index = index
+        self.language = language
+
+        """
+        :linted_start: The start of the section in the linted file.Initially it 
+                       is same as that of the start of the original file. It 
+                       changes only when any patches are applied on that line.
+        :linted_end:   The end of the section in the linted file.Initially it 
+                       is same as that of the end of the original file. It 
+                       changes only when any patches are applied on that line.
+        """
+        self.linted_start = start
+        self.linted_end = end
+
+        if self.start.file != self.end.file:
+            raise ValueError('File of start and end position do not match.')
+
+    @classmethod
+    def from_values(cls,
+                    file,
+                    start_line=None,
+                    start_column=None,
+                    end_line=None,
+                    end_column=None,
+                    index=None,
+                    language=None):
+        start = NlSectionPosition(file, start_line, start_column)
+        if end_line or (end_column and end_column > start_column):
+            end = NlSectionPosition(file, end_line if end_line else start_line,
+                                 end_column)
+        else:
+            end = None
+
+        return cls(start, end, index, language)
+
+
+```
+
+### Note
+
+The implementation of the nested language architecture would be done inside the
+a new folder called as `nestedlib` . This `nestedlib` would be present under
+the `coalib` directory.
+
+
+## Architecture
+
+The following figure depicts the architecture that is going to be implemented
+to enable nested languages support.
+
+![Architecture](https://github.com/Naveenaidu/gsoc-18-materials/blob/master/photos/arch-detailed.jpg)
+
+* __NLCore__
+
+This is the heart of the project. It is responsible to manage the execution flow
+in the program
+
+* __NLInfoExtractor__
+
+NLInfoExtractor is responsible to extract the information from the user's input. 
+The extracted information would include the languages present in the file,
+bears to run for each programming language and the settings of these bears.
+
+* __Parser__
+
+Parser splits up the original nested file into different `nl_sections`.
+
+* __NLFileHandler__
+
+NL FileHandler is responsible for creating the temporary files (_which contains
+all the sections belonging to a single language_) that would be passed for the 
+actual analysis.
+
+## Implementation
+
+This project will be implemented in four phases:
+
+* Information Gathering
+* Segregating the file
+* Linting the file
+* Assembling
+
+## Phase 1: Information Gathering
+
+The users can inform coala about the presence of nested languages in the files
+using the `--handle-nested` flag.
+
+eg:
+```bash
+coala --handle-nested --files=html_php_file.html --language=html,php --bears=HTMLBear,PHPBear 
+```
+
+* `--languages`: Informs coala about the languages present in the file
+* `--bears`: Informs coala about the bears to run on the file. 
+
+The aim of information gathering is to extract the following information from
+the arguments passed to coala:
+1. Languages present in the file
+2. Language and Bear association
+3. Argument list (__would be used to create coala sections__)
+
+The languages present in the file can easily be gathered from the `--language`
+tag. The language and Bear association information can be attained by using
+the meta information of the bear and matching it with the `--languages`.
+
+`NlInfoExtractor` is responsible for the above tasks.
+
+The original nested language file is divided into various temporary 
+in-memory files, where each file contains the snippets of one particular 
+language. The linting needs to be done by the respective bears on each of the
+file. 
+
+In order to do so, we would have to create `virtual coala sections` for
+each file.
+
+Each section, would contain the information about the files to be linted, the
+bears to run on those files and the setting to initialize the bear with. In 
+order to create these sections we would need the `arguments` to be passed to
+the `parse_cli()`  method. The arguments used to initialize coala in nested
+language mode cannot be used to create the coala sections.
+
+The NlInfoExtractor converts the original arguments into different argument list,
+where each argument list resembles the argument that a user would have passed
+if he was linting a single temp_file with the appropriate bears.
+
+For eg:
+
+```bash
+coala --handle-nested --file=html_php_file.html --language=html,php --bears=HTMLBear,PHPBear 
+```
+
+gets converted to:
+
+```bash
+coala --file=temp_html_file --language=html --bears=HTMLBear 
+```
+
+and
+
+```bash
+coala --file=temp_php_file --language=php --bears=PHPBear  
+```
+
+The above arguments when passed to the `parse_cli()` method, creates two
+section:
+
+```bash
+[nl.html]
+files = temp_html_file
+bears = HTMLBear
+setting = value
+
+[nl.php]
+files = temp_php_file
+bears = PHPBear
+setting = value
+```
+
+### NlInfoExtractor.py Prototype
+
+```python
+def extract_info(args):
+	"""
+	Return a dictionary called as `nl_info_dict` with all the extracted 
+	information.
+
+	Let's assume that we have the following arguments
+
+	>>>args = coala --handle-nested --file=html_php_file.html --language=html,php --bears=HTMLBear,PHPBear
+
+	>>> nl_info_dict = extract_info(args)
+
+	>>> nl_info_dict
+	{
+		"file_name": html_php_file.html,
+		"absolute_file_path": /home/test/html_php_file.html,
+		"languages": [html, php]
+		"bears": [HTMLBear, PHPBear]
+		"language_bear_dict": language_bear_dict
+		"arg_dict": arg_dict
+	}
+
+	>>> nl_info_dict['language_bear_dict']
+	{
+		"html": [HTMLBear],
+		"php" : [PHPBear]
+	}
+
+	>>> nl_info_dict['arg_dict']
+	{
+		"nl.html":	{"file_name": "temp_html_file",
+				"bears": 'HTMLBear',
+				"settings": [(setting,value)]
+				}
+		
+		
+		"nl.php": 	{"file_name": "temp_php_file",
+				"bears": 'PHPBear',
+				"settings": [(setting,value)]
+				}
+
+	}
+
+
+	"""
+
+def get_lang_info(args):
+	"""Return a list of langauges present in the nested file"""
+
+def get_bear_info(args):
+	"""Return the list of bears to be run on the file"""
+
+def get_file_info(args):
+	"""Returns the list of files to be linted"""
+
+def get_absolute_file_path(file_name):
+	"""Returns the absolute file path of eacg file"""
+
+def get_language_bear_dict(languages, bears):
+	"""
+	Return a language_bear dict, where each language is mapped to a set of bears
+	"""
+
+def get_argument_dict(file_list, language_bear_dict, settings):
+	"""
+	Returns a argument_dict, where each temp_file is mapped to a set of
+	arguments.
+	"""
+
+```
+different `nl_sections` and creating temporary files for each nested languages,
+which would contain the snippets of that language from the original nested file.
+
+This phase uses the `Parser` and the `NlFileHandler` parts of the architecture.
+
+### Parser
+
+* Parser is responsible for splitting the original file into different 
+`nl_sections`.
+
+* The input and output to the parser is __standardized__, where the input to the 
+parser are the contents of the original nested file and the output is the list
+of nl_sections encompassing the snippets of different programming language.
+
+* Standardizing the parser helps us in removing any restriction on how a parser
+should parse the contents. A parser can also use third party API's as long as
+the output from it is in accordance with the format of a nl_sections.
+
+* Since different combination of languages would need different parsers, we
+would create a new folder at `nestedlib/parsers` which would host the collection
+of all the parsers.
+
+* A new super class called as `Parser` would be created. This would have all the
+common methods that all the parser might need. All the parser would be derived
+from this Superclass.
+
+### Parser.py Prototype
+
+```python
+import coalib.nestedlib.NlSection
+
+class Parser:
+
+	def parse(file_contents):
+		'''
+		Returns a list of nl_sections.
+
+		:param file_contents: The contents of the original nested file
+
+		>>> file_contents = \
+				"""
+				<!DOCTYPE html>
+	 			<head>
+				<title>Hello world as text</title>
+				<?php
+					echo "<p>Hello world</p>";
+				?>
+				</html>
+				"""
+
+		>>> p = Parser()
+		>>> nl_sections = p.parse(file_contents)
+		>>> nl_sections
+		(	<NlSection object(index=1, language=html, orig_start=1, orig_end=3)>,
+			<NlSection object(index=2, language=php, orig_start=4, orig_end=6)>,
+			<NlSection object(index=3, language=html, orig_start=7, orig_end=7)>
+		)
+		'''
+
+	def detect_language(str):
+		"""
+		Return the language of the particulat string.
+
+		This will be overridden by the child class
+		"""
+
+	def create_nl_section(start, end, language, index):
+		"""
+		Creates a NlSection Object from the values.
+
+		Returns the NlSection object
+		"""
+
+		return NlSection.from_values(start=start, end=end, language=language,
+					     index=index)
+
+```
+
+### Making temporary files
+
+This sections deals with how the segregated section (nl_sections) from the 
+parser are combined to form different temporary files on which linting
+will be done. 
+
+`NlFileHandler` is responsible to create the temporary files. These temporary 
+files are stored in the memory.
+
+1. The nl_sections are passed to NlFileHandler.
+
+2. NlFileHander then creates a `nl_file_dict`, where the key is the name of 
+the temporary file and the contents are it's value. It is similar to the
+`file_dict` that is created by coala in `instantiate_process()` during the
+execution of the section.
+
+3. It is important to keep in mind, that the temporary segregated file are not
+actually present in the folder. In the normal flow of coala,during the execution 
+of the coala sections, coala will try to find the files by the filenames 
+mentioned in the coala section. And then create a `file_dict`.
+That cannot happen in our case. So we will explicitly replace the `file_dict` 
+with `nl_file_dict`.   
+
+### NlFileHandler.py Prototype
+
+```python
+def get_nl_file_dict(nl_file_info, nl_sections):
+	"""
+	Returns a nl_file_dict, where the key is the name of the temporary file
+	and the value is the contents of that file.
+
+	:param nl_file_info:	The information extracted from the arguments.
+				This is generated by the NlInfoExtractor.
+	:param nl_sections:	The segregated sections of the original file.
+
+	>>> nl_file_info
+	{
+		"file_name": html_php_file.html,
+		"absolute_file_path": /home/test/html_php_file.html,
+		"languages": [html, php]
+		"bears": [HTMLBear, PHPBear]
+		"language_bear_dict": language_bear_dict
+		"arg_dict": arg_dict
+	}
+
+	>>> nl_sections
+	(	<NlSection object(index=1, language=html, orig_start=1, orig_end=3)>,
+		<NlSection object(index=2, language=php, orig_start=4, orig_end=6)>,
+		<NlSection object(index=3, language=html, orig_start=7, orig_end=7)>
+	)
+
+	>>> file_contents = get_file(nl_file_info['file_name'])
+
+	>>> file_contents = \
+			'''
+			<!DOCTYPE html>
+ 			<head>
+			<title>Hello world as text</title>
+			<?php
+				echo "<p>Hello world</p>";
+			?>
+			</html>
+			'''
+
+	>>> nl_file_dict = get_nl_file_dict(nl_file_info, nl_sections)
+	>>> nl_file_dict
+	{
+		"temp_html_file":('''<!DOCTYPE html>\n
+				<head>\n 
+				<title>Hello world as text</title>\n 
+				\n
+				\n 		
+				\n  
+				</html>'''),
+
+		"temp_php_file":('''\n
+				\n
+				\n
+				\t\t<?php\n
+				\t\t\techo "<p>Hello world</p>";\n
+				\t?>''')
+
+
+	}
+
+	"""
+
+def get_file_contents(file_name):
+	""" Returns the contents of the file"""
+
+def assemble(nl_diff_dict, nl_sections, nl_info_dict):
+	"""
+	Assembles the temporary files. 
+
+	The sections are extracted by their increasing order of their index and 
+	then written directly to the original file.
+	"""
+	file = open(nl_info_dict['absolute_file_path'], 'w')
+
+	for nl_section in sorted(nl_sections.index):
+		temp_file_name = nl_section.temp_file
+		start = nl_section.linted_start
+		end = nl_section.linted_end
+		linted_file_content = nl_diff_dict[temp_file_name]
+
+		section_content = get_file_content(linted_file_content, start, end)
+
+		file.write(section_content)
+
+
+```
+
+## Phase 3: Linting the file
+
+This phase deals with linting the temporary files created by the NlFileHandler using
+the `nl_sections`.
+
+1. In coala the linting of the files are done when the section created by coala
+are executed.
+
+2. Since we are explicitly making the sections for nested languages, care has been 
+taken to keep the file names of the `nl.lang` section and the file names
+in `nl_file_dict`  same.
+
+3. During the execution of the section, in the `instantiate_process()` we do not
+access the physical file, rather we replace the `file_dict` with `nl_file_dict`
+and make the necessary changes.
+
+4. Once the `file_dict` is changed, coala will normally continue the process.
+To coala, it now looks as if the `temporary files` were actually present in the
+physical drive. And the linting starts
+
+### Applying the Patches
+
+Whenever the bears suggests a patch and the user desires to apply the Patch, we
+would also need to update the information of the `linted_start` and 
+`linted_end`. This needs to be done because, whenever a patch is applied the 
+position of the lines might change because of addition and deletion of lines.
+
+Keeping track of the start and end of a particular `nl_section` in the linted
+files would help in easier extraction of the `nl_section` from the temporary
+created files.
+
+In order to do so, we'll have to make changes to the `apply()` method of
+the `ApplyAction`. We use the `update_nl_sections()` functions to update
+the values.
+
+In `Diff.py` we add a new function `get_diff_info()` that would give us the 
+information of the diff
+
+#### Diff.py
+
+```python
+def get_diff_info():
+	"""
+	Returns tuple containing line numbers of deleted,changed and added lines.
+	"""
+	deleted_lines = []
+	added_lines = []
+	changed_lines = []
+
+	for line_nr in self._changes:
+		line_diff = self._changes[line_nr]
+
+		if line_diff.change:
+			changed_lines.append(line_nr)
+		elif line_diff.delete:
+			deleted_lines.append(line_nr)
+		if line_diff.add_after:
+			added_lines.append(line_nr)
+
+	return changed_lines, deleted_lines, added_lines
+```
+
+### NLCore.py
+
+The following method belongs to the NlCore
+
+```python
+from coalib.result_action.Diff import stats,get_diff_info
+
+diff_stats = stats()
+diff_info = get_diff_info()
+
+def find_section_index(diff_stats, diff_info, nl_sections):
+	"""
+	Returns the section index to which the patch is about to be applied.
+	"""
+
+	return index
+
+def update_nl_sections(diff_stats, diff_info, nl_sections):
+	"""
+	Updates the `linted_start` and the `linted_end` of the nl_sections 
+	"""
+
+	index = find_section_index(diff_stats, diff_info, nl_sections)
+
+	for nl_sections in nl_sections:
+		if nl_section.index == index:
+			"""
+			Update the values of linted_start` and the `linted_end`
+			"""
+
+```
+
+## Phase 4: Assembling
+
+This phase deals with assembling the linted temporary files back into the 
+original file.
+
+This phase has two parts:
+
+1. Extracting the sections from the linted temporary files.
+2. Assembling these sections.
+
+Once all the coala sections have been executed, we have a `nl_diff_dict` where
+the key is the name of the temporary file and the value is the contents of the
+linted file contents of the temporary file.
+
+We have a `assemble()` method inside the NlFileHandler, which uses
+the information from the `nl_sections` and extracts the sections from the
+`nl_diff_dict` and write it to the original file
+
+```python
+def assemble(nl_diff_dict, nl_sections, nl_info_dict):
+	"""
+	Assembles the temporary files. 
+
+	The sections are extracted by their increasing order of their index and 
+	then written directly to the original file.
+	"""
+	file = open(nl_info_dict['absolute_file_path'], 'w')
+
+	for nl_section in sorted(nl_sections.index):
+		temp_file_name = nl_section.temp_file
+		start = nl_section.linted_start
+		end = nl_section.linted_end
+		linted_file_content = nl_diff_dict[temp_file_name]
+
+		section_content = get_file_content(linted_file_content, start, end)
+
+		file.write(section_content)
+
+```
+
+## NlCore.py Prototype
+
+```python
+from coalib.nestedlib.NlInfoExtractor import extract_info
+from coalib.result_action.Diff import stats,get_diff_info
+from coalib.nestedlib.NlFileHandler import get_file_contents, get_nl_file_dict, assemble
+
+import coalib.nestedlib.Parser
+
+def get_arg_info(arg):
+	"""
+	Return argument list and nl_info_dict that  will be used to make 
+	the coala sections
+
+	>>> arg_list = get_arg_list(arg)
+	[ ( (file, temp_html_file), (bears, HTMLBear ), (settings, value) ),
+	  ( (file, temp_php_file), (bears, PHPBear ), (settings, value) )
+	]
+
+	"""
+	nl_info_dict = extract_info(arg)
+	arg_list = make_arg_list(nl_info_dict)
+
+	return nl_info_dict, arg_list
+
+def get_file_metadata(nl_info_dict):
+	"""
+	Returns the nl_sections and nl_file_dict
+	"""
+
+	parser = detect_parser(nl_info_dict['languages'])
+	file_contents = get_file_contents(nl_info_dict['absolute_file_path'])
+
+	index = find_section_index(diff_stats, diff_info, nl_sections)
+
+	for nl_sections in nl_sections:
+		if nl_section.index == index:
+			"""
+			Update the values of linted_start` and the `linted_end`
+			"""
+
+
+def assemble_files(nl_diff_dict, nl_sections, nl_info_dict):
+	"""
+	Assembles the file and returns back to coala_main
+	"""
+
+	return assemble(nl_diff_dict, nl_sections, nl_info_dict)
+
+```
+
+## Changes in coala.py
+
+```python
+import coalib.nestedlib.Nlcore
+def main(debug=False):
+	configure_logging()
+	handle_nested = True
+
+	args = None 	# to have args variable in except block 
+					#  when parse_args fails
+	try:
+		args = default_arg_parser().parse_args()
+		if args.handle_nested:
+			nl_info_dict, nl_arg_dict = get_arg_info(args)
+			nl_sections, nl_file_dict = get_file_metadata(nl_info_dict)
+
+		"""
+		
+		Code Contents of of coala.py
+
+		"""
+
+	return mode_normal(console_printer, None, args, debug=debug, 
+			handle_nested, nl_info_dict, nl_arg_dict, 
+			nl_sections, nl_file_dict)
+
+```

